// Configuraci√≥n para integraci√≥n con IA (ChatGPT)
export const AI_CONFIG = {
  // URL de la API de OpenAI
  OPENAI_API_URL: 'https://api.openai.com/v1/chat/completions',
  
  // Modelo a usar (gpt-4, gpt-3.5-turbo, etc.)
  MODEL: 'gpt-4',
  
  // Configuraci√≥n por defecto
  DEFAULT_CONFIG: {
    max_tokens: 2000,
    temperature: 0.7,
    top_p: 1,
    frequency_penalty: 0,
    presence_penalty: 0
  },
  
  // Prompts del sistema
  SYSTEM_PROMPTS: {
    MONITORING_ANALYSIS: `Eres un experto en an√°lisis de sistemas y debugging de aplicaciones web. 
    Tu trabajo es analizar datos de monitoreo y proporcionar:
    
    1. **RESUMEN EJECUTIVO**: Un p√°rrafo que resuma el estado general del sistema
    2. **PROBLEMAS CR√çTICOS**: Lista de los 3-5 problemas m√°s importantes que necesitan atenci√≥n inmediata
    3. **RECOMENDACIONES**: Acciones espec√≠ficas para resolver los problemas identificados
    4. **INSIGHTS DE RENDIMIENTO**: An√°lisis del rendimiento y optimizaciones sugeridas
    5. **PATRONES DE ERRORES**: Patrones identificados en los errores y c√≥mo solucionarlos
    
    Responde en espa√±ol y s√© espec√≠fico y accionable en tus recomendaciones.`,
    
    ERROR_ANALYSIS: `Eres un experto en debugging de aplicaciones web. Analiza los errores proporcionados y:
    
    1. Identifica la causa ra√≠z de cada error
    2. Proporciona soluciones espec√≠ficas
    3. Sugiere medidas preventivas
    4. Prioriza los errores por criticidad
    
    Responde en espa√±ol con recomendaciones t√©cnicas espec√≠ficas.`,
    
    PERFORMANCE_ANALYSIS: `Eres un experto en optimizaci√≥n de rendimiento web. Analiza las m√©tricas proporcionadas y:
    
    1. Identifica cuellos de botella de rendimiento
    2. Sugiere optimizaciones espec√≠ficas
    3. Proporciona m√©tricas objetivo
    4. Recomienda herramientas de monitoreo adicionales
    
    Responde en espa√±ol con recomendaciones t√©cnicas espec√≠ficas.`
  }
};

// Funci√≥n para obtener la API key
export const getOpenAIAPIKey = (): string => {
  // Prioridad: variable de entorno > localStorage > prompt al usuario
  const envKey = import.meta.env.VITE_OPENAI_API_KEY;
  const localKey = localStorage.getItem('openai_api_key');
  
  if (envKey) return envKey;
  if (localKey) return localKey;
  
  // Si no hay API key, pedirla al usuario
  const userKey = prompt(
    'Para usar el an√°lisis con IA, necesitas una API key de OpenAI.\n\n' +
    '1. Ve a https://platform.openai.com/api-keys\n' +
    '2. Crea una nueva API key\n' +
    '3. P√©gala aqu√≠\n\n' +
    'API Key:'
  );
  
  if (userKey && userKey.trim()) {
    localStorage.setItem('openai_api_key', userKey.trim());
    return userKey.trim();
  }
  
  throw new Error('API key de OpenAI requerida para el an√°lisis con IA');
};

// Funci√≥n para hacer llamadas a la API de OpenAI
export const callOpenAI = async (
  prompt: string,
  systemPrompt: string = AI_CONFIG.SYSTEM_PROMPTS.MONITORING_ANALYSIS,
  options: Partial<typeof AI_CONFIG.DEFAULT_CONFIG> = {}
) => {
  try {
    const apiKey = getOpenAIAPIKey();
    
    if (!apiKey) {
      throw new Error('API key de OpenAI no configurada');
    }

    console.log('üîë API Key obtenida:', apiKey.substring(0, 10) + '...');
    console.log('üìù Enviando prompt a OpenAI...');

    const requestBody = {
      model: 'gpt-4o-mini', // Cambio a modelo m√°s econ√≥mico
      messages: [
        {
          role: 'system',
          content: systemPrompt
        },
        {
          role: 'user',
          content: prompt
        }
      ],
      max_tokens: options.max_tokens || 4000,
      temperature: options.temperature || 0.3
    };

    console.log('üì¶ Request body preparado:', {
      model: requestBody.model,
      messagesCount: requestBody.messages.length,
      maxTokens: requestBody.max_tokens
    });

    const response = await window.fetch(AI_CONFIG.OPENAI_API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify(requestBody)
    });

    console.log('üì° Respuesta recibida:', response.status, response.statusText);

    if (!response.ok) {
      const errorText = await response.text();
      console.error('‚ùå Error en respuesta:', errorText);
      throw new Error(`Error en la API de OpenAI: ${response.status} ${response.statusText}`);
    }

    const data = await response.json();
    console.log('‚úÖ Datos recibidos de OpenAI:', data);
    
    if (!data.choices || !data.choices[0] || !data.choices[0].message) {
      throw new Error('Respuesta inv√°lida de OpenAI');
    }

    return data.choices[0].message.content;
  } catch (error) {
    console.error('‚ùå Error en callOpenAI:', error);
    throw error;
  }
};

// Funci√≥n para validar la API key
export const validateAPIKey = async (apiKey: string): Promise<boolean> => {
  try {
    const response = await fetch(AI_CONFIG.OPENAI_API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: 'gpt-3.5-turbo',
        messages: [{ role: 'user', content: 'test' }],
        max_tokens: 1
      })
    });
    
    return response.ok;
  } catch {
    return false;
  }
};

// Funci√≥n para limpiar la API key
export const clearAPIKey = (): void => {
  localStorage.removeItem('openai_api_key');
};

// Funci√≥n para configurar la API key
export const setAPIKey = (apiKey: string): void => {
  localStorage.setItem('openai_api_key', apiKey);
};
